{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a7a8230",
   "metadata": {},
   "source": [
    "# Matrix Factorisation using Similarity Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e224e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tdc.multi_pred import DTI\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import logging\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the dataset\n",
    "data_Kd = DTI(name='BindingDB_Kd')\n",
    "data_Kd.convert_to_log()\n",
    "\n",
    "print(\"load similarity matrix\")\n",
    "drug_sim_np = np.loadtxt('../sim_matrix/drug_sim.txt', delimiter=',')\n",
    "drug_sim = torch.from_numpy(drug_sim_np)\n",
    "\n",
    "target_sim_np = np.loadtxt('../sim_matrix/target_sim_Kd.txt', delimiter=',')\n",
    "target_sim = torch.from_numpy(target_sim_np)\n",
    "print(\"load done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d212ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data):\n",
    "    # split data and get ID dicts\n",
    "    split = data.get_split(seed=42, frac=[0.6, 0.05, 0.35])\n",
    "    train = split['train']\n",
    "    test = split['test']\n",
    "\n",
    "    train = train[['Drug_ID', 'Drug', 'Target', 'Y']].dropna()\n",
    "    train = train.reset_index(drop=True)\n",
    "\n",
    "    ID_to_Drug = dict(enumerate(list(dict.fromkeys(train['Drug_ID']))))\n",
    "    ID_to_Target = dict(enumerate(list(dict.fromkeys(train['Target']))))\n",
    "    Drug_to_ID = dict((v, k) for k, v in ID_to_Drug.items())\n",
    "    Target_to_ID = dict((v, k) for k, v in ID_to_Target.items())\n",
    "\n",
    "    return train, test, Drug_to_ID, Target_to_ID\n",
    "\n",
    "\n",
    "def data_loader(data, drug_dict, target_dict):\n",
    "    # load data into correct format\n",
    "    data[\"Target_ID2\"] = data[\"Target\"].apply(lambda x: target_dict.get(x))\n",
    "    data[\"Drug_ID2\"] = data[\"Drug_ID\"].apply(lambda x: drug_dict.get(x))\n",
    "    data = data.dropna()\n",
    "\n",
    "    drug_ID = data[\"Drug_ID2\"].to_numpy()\n",
    "    target_ID = data[\"Target_ID2\"].to_numpy()\n",
    "    features = np.vstack((drug_ID, target_ID)).T\n",
    "    label = data['Y'].to_numpy()\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09232250",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, train, label):\n",
    "        self.feature_ = train\n",
    "        self.label_ = label\n",
    "\n",
    "    def __len__(self):\n",
    "        # return size of dataset\n",
    "        return len(self.feature_)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.feature_[idx], dtype=torch.long), torch.tensor(self.label_[idx], dtype=torch.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_users, n_items, n_factors, drug_sim, target_sim):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        torch.nn.init.xavier_uniform_(self.user_factors.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.item_factors.weight)\n",
    "\n",
    "        self.user_biases = torch.nn.Embedding(n_users, 1)\n",
    "        self.item_biases = torch.nn.Embedding(n_items, 1)\n",
    "        self.user_biases.weight.data.fill_(0.)\n",
    "        self.item_biases.weight.data.fill_(0.)\n",
    "\n",
    "        self.user_sim = drug_sim\n",
    "        self.item_sim = target_sim\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        AAT_list = [torch.dot(self.user_factors(user)[i, :], self.user_factors(user)[i, :]) for i in\n",
    "                    range(self.user_factors(user).shape[0])]\n",
    "        AAT = torch.tensor(AAT_list)\n",
    "\n",
    "        Sd_partial = self.user_sim[user]\n",
    "        Sd = Sd_partial[:, user]\n",
    "\n",
    "        BBT_list = [torch.dot(self.item_factors(item)[i, :], self.item_factors(item)[i, :]) for i in\n",
    "                    range(self.item_factors(item).shape[0])]\n",
    "        BBT = torch.tensor(BBT_list)\n",
    "\n",
    "        St_partial = self.user_sim[user]\n",
    "        St = St_partial[:, user]\n",
    "\n",
    "        pred = self.user_biases(user) + self.item_biases(item)\n",
    "        pred += (self.user_factors(user) * self.item_factors(item)).sum(1, keepdim=True)\n",
    "\n",
    "        drug_norm = 0.25 * torch.norm(Sd - AAT)\n",
    "        target_norm = 0.25 * torch.norm(St - BBT)\n",
    "        return pred.squeeze(), drug_norm, target_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f30470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, model, num_epochs=100):\n",
    "    dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    model.to(dev)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(0, num_epochs):\n",
    "        count = 0\n",
    "        cum_loss = 0.\n",
    "        for i, (train_batch, label_batch) in enumerate(train_loader):\n",
    "            count = 1 + i\n",
    "            # Predict and calculate loss for user factor and bias\n",
    "            optimizer = torch.optim.SGD([model.user_biases.weight, model.user_factors.weight], lr=0.01,\n",
    "                                        weight_decay=1e-5)\n",
    "            prediction, drug_norm, target_norm = model(train_batch[:, 0].to(dev), train_batch[:, 1].to(dev))\n",
    "            loss = loss_func(prediction, label_batch.to(dev)).float() + drug_norm + target_norm\n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # predict and calculate loss for item factor and bias\n",
    "            optimizer = torch.optim.SGD([model.item_biases.weight, model.item_factors.weight], lr=0.01,\n",
    "                                        weight_decay=1e-5)\n",
    "            prediction, drug_norm, target_norm = model(train_batch[:, 0].to(dev), train_batch[:, 1].to(dev))\n",
    "            loss = loss_func(prediction, label_batch.to(dev)).float() + drug_norm + target_norm\n",
    "            loss_item = loss.item()\n",
    "            cum_loss += loss_item\n",
    "\n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        train_loss = cum_loss / count\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        cum_loss = 0.\n",
    "        count = 0\n",
    "        for i, (test_batch, label_batch) in enumerate(test_loader):\n",
    "            count = 1 + i\n",
    "            with torch.no_grad():\n",
    "                prediction, drug_norm, target_norm = model(test_batch[:, 0].to(dev), test_batch[:, 1].to(dev))\n",
    "                loss = loss_func(prediction, label_batch.to(dev))\n",
    "                cum_loss += loss.item()\n",
    "\n",
    "        test_loss = cum_loss / count\n",
    "        test_losses.append(test_loss)\n",
    "        if epoch % 1 == 0:\n",
    "            print('epoch: ', epoch, ' avg training loss: ', train_loss, ' avg test loss: ', test_loss)\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model(data, drug_sim, target_sim, img_name, n_factors=100, bs=128, num_epochs=100):\n",
    "    train, test, drug_dict, target_dict = data_split(data)\n",
    "    x_train, y_train = data_loader(train, drug_dict, target_dict)\n",
    "    x_test, y_test = data_loader(test, drug_dict, target_dict)\n",
    "\n",
    "    train_dataloader = DataLoader(RatingDataset(x_train, y_train), batch_size=bs, shuffle=True)\n",
    "    test_dataloader = DataLoader(RatingDataset(x_test, y_test), batch_size=bs)\n",
    "\n",
    "    model = MatrixFactorization(len(drug_dict), len(target_dict), n_factors, drug_sim, target_sim)\n",
    "\n",
    "    train_losses, test_losses = train_model(train_dataloader, test_dataloader, model, num_epochs)\n",
    "\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.plot(epochs, train_losses, label='train')\n",
    "    plt.plot(epochs, test_losses, label='test')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('mse loss')\n",
    "    plt.legend()\n",
    "    plt.title(img_name)\n",
    "    #     plt.savefig(img_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model(data_Kd, drug_sim, target_sim, 'Kd', n_factors=100, bs=128, num_epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
