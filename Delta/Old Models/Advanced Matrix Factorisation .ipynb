{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b24cf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "To log space...\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tdc.multi_pred import DTI\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import logging\n",
    "from rdkit import Chem\n",
    "\n",
    "# load in the three datasets\n",
    "data_Kd = DTI(name = 'BindingDB_Kd')\n",
    "data_Kd.convert_to_log(form = 'binding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d75aac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data):\n",
    "    # split data and get ID dicts\n",
    "    split = data.get_split(seed = 42,  frac = [0.6, 0.05, 0.35])\n",
    "    train = split['train']\n",
    "    test = split['test']\n",
    "\n",
    "    train = train[['Drug_ID', 'Drug', 'Target', 'Y']].dropna()\n",
    "    train = train.reset_index(drop=True)\n",
    "\n",
    "    ID_to_Drug = dict(enumerate(list(dict.fromkeys(train['Drug_ID']))))\n",
    "    ID_to_Target = dict(enumerate(list(dict.fromkeys(train['Target']))))\n",
    "    Drug_to_ID = dict((v,k) for k,v in ID_to_Drug.items())\n",
    "    Target_to_ID = dict((v,k) for k,v in ID_to_Target.items())\n",
    "    \n",
    "    return train, test, Drug_to_ID, Target_to_ID\n",
    "\n",
    "def data_loader(data, drug_dict, target_dict):\n",
    "    # load data into correct format\n",
    "    data[\"Target_ID2\"] = data[\"Target\"].apply(lambda x:target_dict.get(x))\n",
    "    data[\"Drug_ID2\"] = data[\"Drug_ID\"].apply(lambda x:drug_dict.get(x))\n",
    "    data = data.dropna()\n",
    "\n",
    "    drug_ID = data[\"Drug_ID2\"].to_numpy()\n",
    "    target_ID = data[\"Target_ID2\"].to_numpy()\n",
    "    features = np.vstack((drug_ID, target_ID)).T\n",
    "    label = data['Y'].to_numpy()\n",
    "    return features, label\n",
    "\n",
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, train, label):\n",
    "        self.feature_= train\n",
    "        self.label_= label\n",
    "    def __len__(self):\n",
    "    #return size of dataset\n",
    "        return len(self.feature_)\n",
    "    def __getitem__(self, idx):\n",
    "        return  torch.tensor(self.feature_[idx], dtype=torch.long),torch.tensor(self.label_[idx], dtype=torch.float)\n",
    "    \n",
    "    \n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors, drug_sim, target_sim):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        torch.nn.init.xavier_uniform_(self.user_factors.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.item_factors.weight)\n",
    "        \n",
    "        self.user_biases = torch.nn.Embedding(n_users, 1)\n",
    "        self.item_biases = torch.nn.Embedding(n_items,1)\n",
    "        self.user_biases.weight.data.fill_(0.)\n",
    "        self.item_biases.weight.data.fill_(0.)\n",
    "        \n",
    "        self.user_sim = drug_sim\n",
    "        self.item_sim = target_sim\n",
    "\n",
    "        \n",
    "    def forward(self, user, item):  \n",
    "        AAT_list = [torch.dot(self.user_factors(user)[i,:], self.user_factors(user)[i,:]) for i in range(self.user_factors(user).shape[0])]\n",
    "        AAT = torch.tensor(AAT_list)\n",
    "        \n",
    "        Sd_partial = self.user_sim[user]\n",
    "        Sd = Sd_partial[:,user]\n",
    "        \n",
    "        BBT_list = [torch.dot(self.item_factors(item)[i,:], self.item_factors(item)[i,:]) for i in range(self.item_factors(item).shape[0])]\n",
    "        BBT = torch.tensor(BBT_list)\n",
    "        \n",
    "        St_partial = self.user_sim[user]\n",
    "        St = St_partial[:,user]\n",
    "        \n",
    "        pred = self.user_biases(user) + self.item_biases(item)\n",
    "        pred += (self.user_factors(user) * self.item_factors(item)).sum(1, keepdim=True)\n",
    "        \n",
    "        pred += (Sd - AAT).sum(1, keepdim=True)\n",
    "        pred += (St - BBT).sum(1, keepdim=True)\n",
    "        return pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "daaa9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, model, num_epochs=100):\n",
    "#     dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    dev = torch.device('cpu')\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    \n",
    "    model.to(dev)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(0,num_epochs):\n",
    "        count = 0\n",
    "        cum_loss = 0.\n",
    "        for i, (train_batch, label_batch) in enumerate(train_loader):\n",
    "            count = 1 + i\n",
    "            # Predict and calculate loss for user factor and bias\n",
    "            optimizer = torch.optim.SGD([model.user_biases.weight,model.user_factors.weight], lr=0.005, weight_decay=1e-5)\n",
    "            prediction = model(train_batch[:,0].to(dev), train_batch[:,1].to(dev))\n",
    "            loss = loss_func(prediction, label_batch.to(dev)).float()    \n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # predict and calculate loss for item factor and bias\n",
    "            optimizer = torch.optim.SGD([model.item_biases.weight,model.item_factors.weight], lr=0.005, weight_decay=1e-5)             \n",
    "            prediction = model(train_batch[:,0].to(dev), train_batch[:,1].to(dev))\n",
    "            loss = loss_func(prediction, label_batch.to(dev))\n",
    "            loss_item = loss.item()\n",
    "            cum_loss += loss_item\n",
    "\n",
    "\n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        train_loss = cum_loss/count\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        cum_loss =0.\n",
    "        count = 0\n",
    "        for i, (test_batch, label_batch) in enumerate(test_loader):\n",
    "            count = 1 + i\n",
    "            with torch.no_grad():\n",
    "                prediction = model(test_batch[:,0].to(dev), test_batch[:,1].to(dev))\n",
    "                loss = loss_func(prediction, label_batch.to(dev))\n",
    "                cum_loss += loss.item()\n",
    "\n",
    "        test_loss = cum_loss/count\n",
    "        test_losses.append(test_loss)\n",
    "        if epoch % 1 == 0:\n",
    "            print('epoch: ', epoch ,' avg training loss: ', train_loss, ' avg test loss: ',test_loss)\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1e1e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model(data, drug_sim, target_sim, img_name, n_factors=100, bs=100, num_epochs=100):\n",
    "    train, test, drug_dict, target_dict = data_split(data)\n",
    "    x_train, y_train = data_loader(train, drug_dict, target_dict)\n",
    "    x_test, y_test = data_loader(test, drug_dict, target_dict)\n",
    "\n",
    "    train_dataloader = DataLoader(RatingDataset(x_train, y_train), batch_size=bs, shuffle=True)\n",
    "    test_dataloader = DataLoader(RatingDataset(x_test, y_test), batch_size=bs)\n",
    "    \n",
    "    model = MatrixFactorization(len(drug_dict), len(target_dict), n_factors, drug_sim, target_sim)\n",
    "\n",
    "    train_losses, test_losses = train_model(train_dataloader, test_dataloader, model, num_epochs)\n",
    "\n",
    "    epochs = range(1, num_epochs+1)\n",
    "    plt.plot(epochs, train_losses, label='train')\n",
    "    plt.plot(epochs, test_losses, label='test')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('mse loss')\n",
    "    plt.legend()\n",
    "    plt.title(img_name)\n",
    "#     plt.savefig(img_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c4c76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_sim_np = np.loadtxt('../sim_matrix/drug_sim.txt', delimiter=',')\n",
    "drug_sim = torch.from_numpy(drug_sim_np)\n",
    "\n",
    "target_sim_np = np.loadtxt('../sim_matrix/target_sim_Kd.txt', delimiter=',')\n",
    "target_sim = torch.from_numpy(target_sim_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0132d5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  avg training loss:  2028.6396204468551  avg test loss:  2124.9282610212053\n",
      "epoch:  1  avg training loss:  1782.856464361689  avg test loss:  1754.060182407924\n",
      "epoch:  2  avg training loss:  1327.0032354464197  avg test loss:  903.303717476981\n",
      "epoch:  3  avg training loss:  531.6020585078343  avg test loss:  124.47464659554618\n",
      "epoch:  4  avg training loss:  136.01215938398033  avg test loss:  68.32819065366472\n",
      "epoch:  5  avg training loss:  76.6872930587477  avg test loss:  83.280856187003\n",
      "epoch:  6  avg training loss:  65.30128406111602  avg test loss:  100.98358880451747\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-7f3bd1e7bfc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfull_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_Kd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrug_sim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Kd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_factors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-9c27525a908e>\u001b[0m in \u001b[0;36mfull_model\u001b[1;34m(data, drug_sim, target_sim, img_name, n_factors, bs, num_epochs)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMatrixFactorization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrug_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_factors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrug_sim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-2ddbc4a1d41c>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_loader, test_loader, model, num_epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m# Predict and calculate loss for user factor and bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_biases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_factors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m# Backpropagate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-9488a28e89a4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, user, item)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mSd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSd_partial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mBBT_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_factors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_factors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_factors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mBBT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBBT_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-9488a28e89a4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mSd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSd_partial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mBBT_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_factors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_factors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_factors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mBBT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBBT_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1850\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_model(data_Kd, drug_sim, target_sim, 'Kd', n_factors=20, bs=100, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a876ec15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
